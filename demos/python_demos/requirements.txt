--extra-index-url https://download.pytorch.org/whl/cpu 

git+https://github.com/dtrawins/optimum-intel.git@concurrency_support_cloneall
## used a fork to provide support for multi concurrency https://github.com/huggingface/optimum-intel/pull/519

onnx==1.17.0
pillow==10.3.0
optimum[diffusers]==1.17.1
tritonclient[grpc]==2.51.0  # Required to use batch string serialization/deserialization (4byte length prepend)
transformers==4.50.0 # 4.50 has a bug
diffusers==0.29.2
datasets==2.18.0
numpy<2.0
huggingface_hub==0.26.0

