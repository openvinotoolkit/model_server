{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "437c0b6d-58ee-4726-8008-93e223ad5cb7",
   "metadata": {},
   "source": [
    "# RAG demo with OpenVINO Model Server and langchain\n",
    "This demo shows how to use Retrieval Augmented Generation with langchain and OpenAI API.\n",
    "\n",
    "It employs the `chat/completion` and `embeddings` endpoints.\n",
    "\n",
    "It assumes the model server is already deployed on the same machine on port 8000 with model `meta-llama/Meta-Llama-3-8B-Instruct` for `chat/completions` and `Alibaba-NLP/gte-large-en-v1.5` for `embeddings` endpoint.\n",
    "\n",
    "Check https://github.com/openvinotoolkit/model_server/tree/main/demos/continuous_batching and https://github.com/openvinotoolkit/model_server/tree/main/demos/embeddings to see how they can be deployed.\n",
    "LLM model and embeddings can be on hosted on the same model server instance or separately as needed.\n",
    "openai_api_base parameter with the target url and model_name in the commands might need to be adjusted. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a498b22-fb7f-4fa1-a4d8-a0d983eb4565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5158e553-3355-46af-879b-e7ef09058aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Document Splitter\n",
    "from typing import List\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter, MarkdownTextSplitter\n",
    "from langchain_community.document_loaders import (\n",
    "    CSVLoader,\n",
    "    EverNoteLoader,\n",
    "    PDFMinerLoader,\n",
    "    TextLoader,\n",
    "    UnstructuredEPubLoader,\n",
    "    UnstructuredHTMLLoader,\n",
    "    UnstructuredMarkdownLoader,\n",
    "    UnstructuredODTLoader,\n",
    "    UnstructuredPowerPointLoader,\n",
    "    UnstructuredWordDocumentLoader, )\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b52e35-ea8a-4c84-b98c-24f774b03721",
   "metadata": {},
   "source": [
    "The documents to scan with knowledge context are to be placed in ./docs folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25410751-e4a5-4348-8376-938dc4ffd959",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FOLDER = \"./docs/\"\n",
    "\n",
    "TEXT_SPLITERS = {\n",
    "    \"Character\": CharacterTextSplitter,\n",
    "    \"RecursiveCharacter\": RecursiveCharacterTextSplitter,\n",
    "    \"Markdown\": MarkdownTextSplitter,\n",
    "}\n",
    "\n",
    "LOADERS = {\n",
    "    \".csv\": (CSVLoader, {}),\n",
    "    \".doc\": (UnstructuredWordDocumentLoader, {}),\n",
    "    \".docx\": (UnstructuredWordDocumentLoader, {}),\n",
    "    \".enex\": (EverNoteLoader, {}),\n",
    "    \".epub\": (UnstructuredEPubLoader, {}),\n",
    "    \".html\": (UnstructuredHTMLLoader, {}),\n",
    "    \".md\": (UnstructuredMarkdownLoader, {}),\n",
    "    \".odt\": (UnstructuredODTLoader, {}),\n",
    "    \".pdf\": (PDFMinerLoader, {}),\n",
    "    \".ppt\": (UnstructuredPowerPointLoader, {}),\n",
    "    \".pptx\": (UnstructuredPowerPointLoader, {}),\n",
    "    \".txt\": (TextLoader, {\"encoding\": \"utf8\"}),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b57421-d418-4c4d-bd98-21d67e7fd31d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  728k    0  728k    0     0  2094k      0 --:--:-- --:--:-- --:--:-- 2099k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  753k    0  753k    0     0  3677k      0 --:--:-- --:--:-- --:--:-- 3693k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  732k    0  732k    0     0  2847k      0 --:--:-- --:--:-- --:--:-- 2859k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  751k    0  751k    0     0  3777k      0 --:--:-- --:--:-- --:--:-- 3795k\n"
     ]
    }
   ],
   "source": [
    "!curl https://docs.openvino.ai/2024/ovms_what_is_openvino_model_server.html --create-dirs -o ./docs/ovms_what_is_openvino_model_server.html\n",
    "!curl https://docs.openvino.ai/2024/ovms_docs_metrics.html -o ./docs/ovms_docs_metrics.html\n",
    "!curl https://docs.openvino.ai/2024/ovms_docs_streaming_endpoints.html -o ./docs/ovms_docs_streaming_endpoints.html\n",
    "!curl https://docs.openvino.ai/2024/ovms_docs_target_devices.html -o ./docs/ovms_docs_target_devices.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed9afff-df0f-42f2-8aa7-6b5fff9f794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_document(file_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    helper for loading a single document\n",
    "\n",
    "    Params:\n",
    "      file_path: document path\n",
    "    Returns:\n",
    "      documents loaded\n",
    "\n",
    "    \"\"\"\n",
    "    ext = \".\" + file_path.rsplit(\".\", 1)[-1]\n",
    "    if ext in LOADERS:\n",
    "        loader_class, loader_args = LOADERS[ext]\n",
    "        loader = loader_class(file_path, **loader_args)\n",
    "        return loader.load()\n",
    "\n",
    "    raise ValueError(f\"File does not exist '{ext}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75374e4c-3af8-44fa-ad8d-f905766cc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"Alibaba-NLP/gte-large-en-v1.5\",\n",
    "    api_key=\"unused\",\n",
    "    tiktoken_enabled=False,\n",
    "    base_url=\"http://localhost:8000/v3\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d12abca7-3074-4c87-8ba1-eb27e4332860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading document ./docs/ovms_docs_streaming_endpoints.html...\n",
      "Reading document ./docs/ovms_docs_metrics.html...\n",
      "Reading document ./docs/ovms_what_is_openvino_model_server.html...\n",
      "Reading document ./docs/ovms_docs_target_devices.html...\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for file_path in os.listdir(TARGET_FOLDER):\n",
    "    if not file_path.endswith('.html'):\n",
    "        continue\n",
    "    abs_path = os.path.join(TARGET_FOLDER, file_path)\n",
    "    print(f\"Reading document {abs_path}...\", flush=True)\n",
    "    documents.extend(load_single_document(abs_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "173aee0c-9cfc-4ad6-bdb5-68df52b797f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "spliter_name = \"RecursiveCharacter\"  # PARAM\n",
    "chunk_size=1000  # PARAM\n",
    "chunk_overlap=200  # PARAM\n",
    "text_splitter = TEXT_SPLITERS[spliter_name](chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281c64d8-e188-4712-8aaa-c2d2eb61c773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dtrawins/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    db.delete_collection()\n",
    "except:\n",
    "    pass\n",
    "db = FAISS.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf2d944-cba1-44d5-8b9a-fccc7860bb4e",
   "metadata": {},
   "source": [
    "The commands below can be used to test the retriever. It can report the content for a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc958cd3-72e6-4311-a77f-44eaa147b2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='OpenVINO Workflow\\n\\n\\n\\nModel Server Features\\n\\nMetrics\\n\\nMetrics#\\n\\nIntroduction#\\n\\nThis document describes how to use metrics endpoint in the OpenVINO Model Server. They can be applied for:\\n\\nProviding performance and utilization statistics for monitoring and benchmarking purposes\\n\\nAuto scaling of the model server instances in Kubernetes and OpenShift based on application related metrics\\n\\nBuilt-in metrics allow tracking the performance without any extra logic on the client side or using network traffic monitoring tools like load balancers or reverse-proxies.\\n\\nIt also exposes metrics which are not related to the network traffic.\\n\\nFor example, statistics of the inference execution queue, model runtime parameters etc. They can also track the usage based on model version, API type or requested endpoint methods.\\n\\nOpenVINO Model Server metrics are compatible with Prometheus standard\\n\\nThey are exposed on the /metrics endpoint.\\n\\nAvailable metrics families#' metadata={'source': './docs/ovms_docs_metrics.html'}\n",
      "page_content='Labels description\\n\\nName Values Description api KServe, TensorFlowServing, V3 Name of the serving API. interface REST, gRPC Name of the serving interface. method ModelMetadata, ModelReady, ModelInfer, Predict, GetModelStatus, GetModelMetadata, Unary, Stream Interface methods. version 1, 2, …, n Model version. Note that GetModelStatus and ModelReady and all MediaPipe servables do not have the version label. name As defined in model server config Model name, DAG name or MediaPipe graph name.\\n\\nEnable metrics#\\n\\nBy default, the metrics feature is disabled.\\n\\nMetrics endpoint is using the same port as the REST interface for running the model queries.\\n\\nIt is required to enable REST in the model server by setting the parameter –rest_port.\\n\\nTo enable default metrics set you need to specify the metrics_enable flag or json setting:\\n\\nOption 1: CLI#\\n\\nwget\\n\\nN\\n\\nhttps://storage.openvinotoolkit.org/repositories/open_model_zoo/2022.1/models_bin/2/resnet50-binary-0001/FP32-INT1/resnet50-binary-0001.' metadata={'source': './docs/ovms_docs_metrics.html'}\n",
      "page_content='OpenVINO Model Server metrics are compatible with Prometheus standard\\n\\nThey are exposed on the /metrics endpoint.\\n\\nAvailable metrics families#\\n\\nMetrics from default list are enabled with the metrics_enable flag or json configuration.\\n\\nHowever, you can enable also additional metrics by listing all the metrics you want to enable in the metric_list flag or json configuration.\\n\\nDefault metrics' metadata={'source': './docs/ovms_docs_metrics.html'}\n"
     ]
    }
   ],
   "source": [
    "vector_search_top_k = 3\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": vector_search_top_k})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"Which metrics are supported in the model server? Give examples.\")\n",
    "print(retrieved_docs[0])\n",
    "print(retrieved_docs[1])\n",
    "print(retrieved_docs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29941c55-e781-42a0-b578-2e463e1b879d",
   "metadata": {},
   "source": [
    "Change the base url and model name depending on the model server deployment and configuration. It is important to use /v3/ part which is specific for the OpenVINO Model Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73d6a7cc-de79-4255-81b3-80ed44f2ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    openai_api_key=\"EMPTY\",\n",
    "    openai_api_base=\"http://localhost:8000/v3\",\n",
    "    model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    temperature=0.0,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ba4bc8d-abab-4374-9776-2f531ba62f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt input_variables=['context', 'question'] template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prompt=PromptTemplate(input_variables=['context', 'question'], \n",
    "                      template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\")\n",
    "\n",
    "print(\"prompt\", prompt)\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5109c9-a43d-4f33-be41-8f982ead321c",
   "metadata": {},
   "source": [
    "Below you can start the RAG chain using your own query. It will call the embedding model first, retrieve the relevant context and pass it to the LLM endpoint in a single request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd5b1d12-0b36-4818-a6e5-d94868c8c970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the provided context, the OpenVINO Model Server supports the following metrics:\n",
      "\n",
      "* api: KServe, TensorFlowServing, V3\n",
      "* interface: REST, gRPC\n",
      "* method: ModelMetadata, ModelReady, ModelInfer, Predict, GetModelStatus, GetModelMetadata, Unary, Stream\n",
      "* version: 1, 2, …, n\n",
      "* name: As defined in model server config Model name, DAG name or MediaPipe graph name\n",
      "\n",
      "These metrics are exposed on the /metrics endpoint and are compatible with the Prometheus standard. Additionally, the model server allows enabling additional metrics by listing them in the metric_list flag or json configuration."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"Which metrics are supported in the model server? Give examples.\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58217565-fc81-454c-87c7-9590de2c4fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
